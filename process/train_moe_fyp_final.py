import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
import os
import sys
import numpy as np
import pandas as pd  # æ–°å¢ï¼šç”¨äºä¿å­˜ CSV è¡¨æ ¼
import matplotlib.pyplot as plt # æ–°å¢ï¼šç”¨äºç”»å›¾
from sklearn.metrics import cohen_kappa_score, f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay

# ================= è·¯å¾„é…ç½® =================
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
structure_path = os.path.join(project_root, 'structure')
model_path = os.path.join(structure_path, 'model')

if structure_path not in sys.path: sys.path.append(structure_path)
if model_path not in sys.path: sys.path.append(model_path)

# === æ–°å¢ï¼šç»“æœè¾“å‡ºè·¯å¾„ ===
RESULT_DIR = r"C:\Users\å·«é€\Desktop\å­¦ä¹ \å¤§å››\æ¯•è®¾\code\result"
if not os.path.exists(RESULT_DIR):
    os.makedirs(RESULT_DIR)
    print(f"ğŸ“ å·²åˆ›å»ºç»“æœæ–‡ä»¶å¤¹: {RESULT_DIR}")
else:
    print(f"ğŸ“ ç»“æœå°†ä¿å­˜è‡³: {RESULT_DIR}")
# ===========================================

from dataset_loader import UniversalEEGDataset
from model_moe import Model_MoE_Final

CONFIG = {
    'data_root': r"D:\fyp\dataset_processed_fbcsp_all",
    'pretrained_path': r"checkpoints_final/model_a_fscfp_2_best.pth",
    'batch_size': 16,     
    'lr': 0.0001,
    'epochs': 80,         
    'n_bands': 55,
    'device': 'cuda:0',
    'snr_aug': True,
    'snr_prob': 0.8,
    'num_segments': 10,
    'subjects': ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09']
}

# === Label Smoothing Loss ===
class LabelSmoothingLoss(nn.Module):
    def __init__(self, classes, smoothing=0.1, dim=-1):
        super(LabelSmoothingLoss, self).__init__()
        self.confidence = 1.0 - smoothing
        self.smoothing = smoothing
        self.cls = classes
        self.dim = dim

    def forward(self, pred, target):
        pred = pred.log_softmax(dim=self.dim)
        with torch.no_grad():
            true_dist = torch.zeros_like(pred)
            true_dist.fill_(self.smoothing / (self.cls - 1))
            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)
        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))

def load_pretrained_weights(model, path):
    if os.path.exists(path):
        checkpoint = torch.load(path)
        if 'frontend' in checkpoint:
            model.frontend.load_state_dict(checkpoint['frontend'])
        if 'encoder' in checkpoint:
            src_state = checkpoint['encoder']
            for i in range(4): 
                prefix_src = f"layers.{i}."
                for suffix in ['in_proj_weight', 'in_proj_bias', 'out_proj.weight', 'out_proj.bias']:
                    src_key = f"{prefix_src}self_attn.{suffix}"
                    if src_key in src_state:
                        if suffix == 'in_proj_weight': model.layers[i].attn.in_proj_weight.data = src_state[src_key].data
                        if suffix == 'in_proj_bias': model.layers[i].attn.in_proj_bias.data = src_state[src_key].data
                        if suffix == 'out_proj.weight': model.layers[i].attn.out_proj.weight.data = src_state[src_key].data
                        if suffix == 'out_proj.bias': model.layers[i].attn.out_proj.bias.data = src_state[src_key].data
                model.layers[i].norm1.weight.data = src_state[f"{prefix_src}norm1.weight"].data
                model.layers[i].norm1.bias.data = src_state[f"{prefix_src}norm1.bias"].data
                model.layers[i].norm2.weight.data = src_state[f"{prefix_src}norm2.weight"].data
                model.layers[i].norm2.bias.data = src_state[f"{prefix_src}norm2.bias"].data
        return True
    return False

def train_individual_subject(subject_id):
    print(f"\nâš¡ æ­£åœ¨å¾®è°ƒå—è¯•è€…: {subject_id}")
    
    train_dataset = UniversalEEGDataset(
        CONFIG['data_root'], mode='train', augment=True, target_dataset=subject_id,
        snr_aug=CONFIG['snr_aug'], snr_prob=CONFIG['snr_prob'], num_segments=CONFIG['num_segments']
    )
    test_dataset = UniversalEEGDataset(CONFIG['data_root'], mode='test', augment=False, target_dataset=subject_id)
    
    if len(train_dataset) == 0: 
        return {'subject': subject_id, 'acc': 0.0, 'kappa': 0.0, 'f1': 0.0}

    train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True, drop_last=True, num_workers=0, pin_memory=True)
    test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0, pin_memory=True)

    model = Model_MoE_Final(
        n_classes=2, n_bands=CONFIG['n_bands'], n_csp=8, time_steps=512,
        embed_dim=128, depth=4, heads=8, num_experts=8, top_k=2, dropout=0.5 
    ).to(CONFIG['device'])
    
    load_pretrained_weights(model, CONFIG['pretrained_path'])
    
    optimizer = optim.AdamW([
        {'params': model.frontend.parameters(), 'lr': CONFIG['lr'] * 0.1}, 
        {'params': model.layers.parameters(), 'lr': CONFIG['lr']},         
        {'params': model.cls_head.parameters(), 'lr': CONFIG['lr']}
    ], weight_decay=0.1)
    
    criterion = LabelSmoothingLoss(classes=2, smoothing=0.1)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=40, T_mult=1)
    
    best_metrics = {'subject': subject_id, 'acc': 0.0, 'kappa': 0.0, 'f1': 0.0, 'preds': [], 'targets': []}
    
    for epoch in range(CONFIG['epochs']):
        # Training
        model.train()
        for x, y in train_loader:
            x, y = x.to(CONFIG['device']), y.to(CONFIG['device'])
            if y.max() > 1: y = torch.where(y == y.min(), torch.tensor(0).to(y.device), torch.tensor(1).to(y.device))
            
            optimizer.zero_grad()
            outputs, aux_loss = model(x)
            loss = criterion(outputs, y) + 0.1 * aux_loss
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
        
        scheduler.step()
            
        # Evaluation
        model.train() # TTA Mode
        epoch_preds = []
        epoch_targets = []
        
        with torch.no_grad():
            for x, y in test_loader:
                x, y = x.to(CONFIG['device']), y.to(CONFIG['device'])
                if y.max() > 1: y = torch.where(y == y.min(), torch.tensor(0).to(y.device), torch.tensor(1).to(y.device))
                
                tta_logits = []
                for _ in range(7): # é™ä½ä¸€ç‚¹TTAæ¬¡æ•°ä»¥åŠ å¿«é€Ÿåº¦ï¼Œå¦‚éœ€æé™ç²¾åº¦å¯æ”¹å›9
                    logits, _ = model(x)
                    tta_logits.append(logits)
                
                avg_logits = torch.stack(tta_logits).mean(0)
                _, predicted = torch.max(avg_logits.data, 1)
                
                epoch_preds.extend(predicted.cpu().numpy())
                epoch_targets.extend(y.cpu().numpy())
        
        cur_acc = accuracy_score(epoch_targets, epoch_preds) * 100
        
        if cur_acc > best_metrics['acc']:
            best_metrics['acc'] = cur_acc
            best_metrics['kappa'] = cohen_kappa_score(epoch_targets, epoch_preds)
            best_metrics['f1'] = f1_score(epoch_targets, epoch_preds, average='macro')
            best_metrics['preds'] = epoch_preds
            best_metrics['targets'] = epoch_targets

    # === ä¿å­˜è¯¦ç»†ç»“æœåˆ°æ–‡ä»¶å¤¹ ===
    print(f"âœ… {subject_id} æœ€ä½³å‡†ç¡®ç‡: {best_metrics['acc']:.2f}% | ä¿å­˜ç»“æœä¸­...")
    
    # 1. ä¿å­˜ çœŸå®å€¼ vs é¢„æµ‹å€¼ è¡¨æ ¼
    df_pred = pd.DataFrame({
        'Sample_Index': range(len(best_metrics['targets'])),
        'True_Label': best_metrics['targets'],
        'Predicted_Label': best_metrics['preds'],
        'Correct': [t == p for t, p in zip(best_metrics['targets'], best_metrics['preds'])]
    })
    csv_path = os.path.join(RESULT_DIR, f"{subject_id}_predictions.csv")
    df_pred.to_csv(csv_path, index=False)
    
    # 2. ç»˜åˆ¶å¹¶ä¿å­˜ æ··æ·†çŸ©é˜µå›¾
    cm = confusion_matrix(best_metrics['targets'], best_metrics['preds'])
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Class 0', 'Class 1'])
    
    fig, ax = plt.subplots(figsize=(6, 5))
    disp.plot(cmap='Blues', ax=ax)
    plt.title(f'Confusion Matrix - {subject_id}\nAcc: {best_metrics["acc"]:.2f}%')
    cm_path = os.path.join(RESULT_DIR, f"{subject_id}_confusion_matrix.png")
    plt.savefig(cm_path)
    plt.close(fig) # å…³é—­å›¾åƒé˜²æ­¢å†…å­˜æ³„æ¼

    return best_metrics

def main():
    results = []
    print(f"ğŸš€ å¼€å§‹ Subject-Specific è®­ç»ƒï¼Œç»“æœå°†ä¿å­˜è‡³: {RESULT_DIR}")
    
    for subj in CONFIG['subjects']:
        res = train_individual_subject(subj)
        # ç§»é™¤è¯¦ç»†åˆ—è¡¨æ•°æ®ï¼Œåªä¿ç•™æŒ‡æ ‡ç”¨äºæ±‡æ€»
        summary_res = {k: v for k, v in res.items() if k not in ['preds', 'targets']}
        results.append(summary_res)
    
    # === æœ€ç»ˆæ±‡æ€» ===
    print("\n" + "="*60)
    print("ğŸ† æœ€ç»ˆç»“æœæ±‡æ€»")
    print("="*60)
    
    df_summary = pd.DataFrame(results)
    
    # è®¡ç®—å¹³å‡å€¼è¡Œ
    avg_row = df_summary[['acc', 'kappa', 'f1']].mean().to_dict()
    avg_row['subject'] = 'AVERAGE'
    df_summary = pd.concat([df_summary, pd.DataFrame([avg_row])], ignore_index=True)
    
    # æ‰“å°åˆ°æ§åˆ¶å°
    print(df_summary.to_string(index=False, float_format="%.4f"))
    
    # ä¿å­˜æ±‡æ€» CSV
    summary_path = os.path.join(RESULT_DIR, "final_summary_metrics.csv")
    df_summary.to_csv(summary_path, index=False)
    print(f"\nğŸ“„ æ±‡æ€»ç»“æœå·²ä¿å­˜è‡³: {summary_path}")
    print(f"ğŸ“„ è¯¦ç»†é¢„æµ‹è¡¨å’Œæ··æ·†çŸ©é˜µå·²ä¿å­˜è‡³: {RESULT_DIR}")
    print("="*60)

if __name__ == "__main__":
    main()